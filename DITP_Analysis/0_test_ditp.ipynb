{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import certifi\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import boto3\n",
    "\n",
    "from utils.analysis_utils import (\n",
    "    format_ligne,\n",
    "    get_elementary_subjects_for_part_of_feedback,\n",
    "    apply_topic_processing,\n",
    "    update_splitted_analysis\n",
    ")\n",
    "from utils.database import (\n",
    "    update_feedbacks,\n",
    "    insert_new_elementary_subjects,\n",
    "    get_elementary_subjects\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "# Constants\n",
    "LANGUAGE = 'french'\n",
    "BRAND_NAME = 'ditp_analysis'\n",
    "MONGO_SECRET_ID = 'Prod/alloreview'\n",
    "MONGO_REGION = 'eu-west-3'\n",
    "MONGO_DATABASE = 'feedbacks_db'\n",
    "MONGO_COLLECTION = 'feedbacks_Prod'\n",
    "SAMPLE_SIZE = 100  # Adjust as needed\n",
    "MODEL_NAME = 'gpt-4o-mini'  # Adjust as needed\n",
    "MAX_WORKERS = 10  # Adjust based on your system and API rate limits\n",
    "\n",
    "def get_mongo_client():\n",
    "    \"\"\"\n",
    "    Establishes a connection to the MongoDB client using credentials from AWS Secrets Manager or environment variables.\n",
    "    \"\"\"\n",
    "    mongo_uri = os.getenv('MONGO_CONNECTION_STRING')\n",
    "    if not mongo_uri:\n",
    "        secrets_manager_client = boto3.client(\"secretsmanager\", region_name=MONGO_REGION)\n",
    "        secrets = json.loads(\n",
    "            secrets_manager_client.get_secret_value(\n",
    "                SecretId=MONGO_SECRET_ID\n",
    "            )[\"SecretString\"]\n",
    "        )\n",
    "        password = secrets[\"mongodb\"][\"password\"]\n",
    "        mongo_uri = f\"mongodb+srv://alloreview:{password}@feedbacksdev.cuwx1.mongodb.net\"\n",
    "\n",
    "    return MongoClient(mongo_uri, tlsCAFile=certifi.where())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Establish MongoDB connection\n",
    "mongo_client = get_mongo_client()\n",
    "collection = mongo_client[MONGO_DATABASE][MONGO_COLLECTION]\n",
    "\n",
    "def get_feedbacks_to_process(collection, brand_name, sample_size):\n",
    "    \"\"\"\n",
    "    Retrieves feedback documents from MongoDB that need processing.\n",
    "\n",
    "    :param collection: MongoDB collection object.\n",
    "    :param brand_name: Name of the brand to filter.\n",
    "    :param sample_size: Number of documents to sample.\n",
    "    :return: DataFrame containing feedbacks to process.\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        '$and': [\n",
    "            {'brand': brand_name},\n",
    "            {'extractions': {'$exists': True, '$not': {'$size': 0}}},\n",
    "            {'splitted_analysis_v2': {'$exists': True, '$not': {'$size': 0}}},\n",
    "            {'extractions': {'$not': {'$elemMatch': {'elementary_subjects': {'$exists': True}}}}}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    pipeline = [\n",
    "        {'$match': query},\n",
    "        {'$sample': {'size': sample_size}}\n",
    "    ]\n",
    "\n",
    "    feedbacks_cursor = collection.aggregate(pipeline)\n",
    "    feedbacks = list(feedbacks_cursor)\n",
    "    return pd.DataFrame(feedbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Retrieve feedbacks to process\n",
    "df_feedbacks = get_feedbacks_to_process(collection, BRAND_NAME, SAMPLE_SIZE)\n",
    "logger.info(f\"Number of feedbacks retrieved: {df_feedbacks.shape[0]}\")\n",
    "\n",
    "if df_feedbacks.empty:\n",
    "    logger.info(\"No feedbacks to process.\")\n",
    "else:\n",
    "    # Select relevant columns\n",
    "    df_feedbacks = df_feedbacks[[\n",
    "        '_id', 'ecrit_le', 'splitted_analysis_v2', 'extractions',\n",
    "        'intitule_structure_1', 'intitule_structure_2', 'tags_metiers', 'pays', 'verbatims'\n",
    "    ]]\n",
    "\n",
    "    # Generate brand_context column\n",
    "    df_feedbacks['brand_context'] = df_feedbacks.apply(format_ligne, axis=1)\n",
    "\n",
    "    # Prepare DataFrame for processing\n",
    "    df_to_process = df_feedbacks[['_id', 'extractions', 'brand_context']]\n",
    "    logger.info(f\"Number of rows pending elementary_subjects processing: {df_to_process.shape[0]}\")\n",
    "\n",
    "    # Explode 'extractions' to have one extraction per row\n",
    "    df_extractions = df_to_process.explode('extractions').reset_index(drop=True)\n",
    "    logger.info(f\"Number of extractions to process: {df_extractions.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # %%\n",
    "    # Function to process each extraction row\n",
    "    def process_extraction_row(row: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Processes a single extraction row to add elementary_subjects.\n",
    "\n",
    "        :param row: Pandas Series representing a row with '_id', 'extractions', and 'brand_context'.\n",
    "        :return: Updated row with 'extractions' and 'elementary_subjects' fields.\n",
    "        \"\"\"\n",
    "        extraction = row['extractions']\n",
    "        try:\n",
    "            extraction, elementary_subjects = get_elementary_subjects_for_part_of_feedback(\n",
    "                extractions=extraction,\n",
    "                language=LANGUAGE,\n",
    "                brand_name=BRAND_NAME,\n",
    "                brand_context=row['brand_context'],\n",
    "                model=MODEL_NAME,\n",
    "                should_update_mongo=False\n",
    "            )\n",
    "            row['extractions'] = extraction\n",
    "            row['elementary_subjects'] = elementary_subjects\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing extraction for _id {row['_id']}: {e}\")\n",
    "            row['elementary_subjects'] = []\n",
    "        return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # %%\n",
    "    # Function to process extractions in parallel\n",
    "    def process_extractions_in_parallel(df: pd.DataFrame, func, max_workers=10) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Processes the extractions DataFrame in parallel using threads.\n",
    "\n",
    "        :param df: DataFrame containing extractions to process.\n",
    "        :param func: Function to apply to each row.\n",
    "        :param max_workers: Maximum number of worker threads.\n",
    "        :return: DataFrame with processed extractions.\n",
    "        \"\"\"\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            results = list(executor.map(func, [row for _, row in df.iterrows()]))\n",
    "        return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # %%\n",
    "    # Process extractions in parallel\n",
    "    df_processed_extractions = process_extractions_in_parallel(\n",
    "        df_extractions, process_extraction_row, max_workers=MAX_WORKERS\n",
    "    )\n",
    "\n",
    "    # Group by '_id' and aggregate 'extractions' into lists\n",
    "    df_grouped = df_processed_extractions.groupby('_id').agg({\n",
    "        'extractions': list,\n",
    "        'brand_context': 'first'  # Keep 'brand_context' for later use\n",
    "    }).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # %%\n",
    "    # Retrieve existing elementary subjects per sentiment type\n",
    "    existing_topics_by_sentiment = {}\n",
    "    for sentiment in ['negative', 'positive', 'suggestion']:\n",
    "        existing_subjects = get_elementary_subjects(BRAND_NAME, sentiment)\n",
    "        existing_topics_by_sentiment[sentiment.upper()] = [item['elementary_subject'] for item in existing_subjects]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # %%\n",
    "    # Function to apply topic processing to extractions\n",
    "    def process_extractions_with_topics(row):\n",
    "        \"\"\"\n",
    "        Processes extractions by applying topic processing.\n",
    "        \"\"\"\n",
    "        extractions = row['extractions']\n",
    "        processed_extractions = apply_topic_processing(extractions, existing_topics_by_sentiment)\n",
    "        row['extractions'] = processed_extractions\n",
    "        return row\n",
    "\n",
    "    # Process extractions with topic processing in parallel\n",
    "    df_grouped = process_extractions_in_parallel(\n",
    "        df_grouped, process_extractions_with_topics, max_workers=MAX_WORKERS\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # %%\n",
    "    # Function to bulk insert elementary subjects\n",
    "    def bulk_insert_elementary_subjects(df, insert_function, brand):\n",
    "        \"\"\"\n",
    "        Prepares and performs bulk insertion of new elementary_subjects into MongoDB\n",
    "        for each row in the DataFrame.\n",
    "\n",
    "        :param df: DataFrame containing 'extractions' column.\n",
    "        :param insert_function: Function to perform the insertion in MongoDB.\n",
    "        :param brand: Brand name to associate with the elementary_subjects.\n",
    "        \"\"\"\n",
    "        all_elementary_subjects = {}\n",
    "        for _, row in df.iterrows():\n",
    "            extractions = row['extractions']\n",
    "            for extraction in extractions:\n",
    "                subjects = extraction.get('elementary_subjects', [])\n",
    "                sentiment = extraction.get('sentiment', 'UNKNOWN')  # Default to UNKNOWN if sentiment is missing\n",
    "                for subject in subjects:\n",
    "                    # Store the elementary_subject along with its sentiment as type\n",
    "                    all_elementary_subjects[subject] = sentiment\n",
    "\n",
    "        # Prepare the list of elementary_subjects to insert\n",
    "        subjects_to_insert = [\n",
    "            {\n",
    "                \"elementary_subject\": subject,\n",
    "                \"type\": sentiment,  # Use the sentiment as type\n",
    "            }\n",
    "            for subject, sentiment in all_elementary_subjects.items()\n",
    "        ]\n",
    "\n",
    "        # Call the insert function with the list of subjects to insert\n",
    "        insert_function(subjects_to_insert, brand)\n",
    "\n",
    "    # Bulk insert new elementary subjects\n",
    "    bulk_insert_elementary_subjects(df_grouped, insert_new_elementary_subjects, brand=BRAND_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # %%\n",
    "    # Update 'splitted_analysis_v2' column\n",
    "    df_grouped['splitted_analysis_v2'] = df_grouped.apply(\n",
    "        lambda row: update_splitted_analysis(row['_id'], row['extractions'], 'splitted_analysis_v2'),\n",
    "        axis=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # %%\n",
    "    # Function to bulk update feedbacks in MongoDB\n",
    "    def bulk_update_feedbacks_from_dataframe(df, update_function):\n",
    "        \"\"\"\n",
    "        Prepares and performs bulk update of feedback documents in MongoDB.\n",
    "\n",
    "        :param df: DataFrame containing '_id', 'extractions', and 'splitted_analysis_v2' columns.\n",
    "        :param update_function: Function to perform the update in MongoDB.\n",
    "        \"\"\"\n",
    "        feedbacks_to_update = [\n",
    "            {\n",
    "                \"id\": row['_id'],\n",
    "                \"updates\": {\n",
    "                    \"extractions\": row['extractions'],\n",
    "                    \"splitted_analysis_v2\": row['splitted_analysis_v2'],\n",
    "                    \"topics_v2\": []\n",
    "                }\n",
    "            }\n",
    "            for _, row in df.iterrows()\n",
    "        ]\n",
    "        # Call the update function with the list of feedback updates\n",
    "        update_function(feedbacks_to_update)\n",
    "\n",
    "    # Perform bulk update\n",
    "    bulk_update_feedbacks_from_dataframe(df_grouped, update_feedbacks)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
